{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26816bd0",
   "metadata": {},
   "source": [
    "# 环境配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f08e0ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting transformers==4.6\n",
      "  Downloading transformers-4.6.0-py3-none-any.whl (2.3 MB)\n",
      "     |████████████████████████████████| 2.3 MB 19.8 MB/s            \n",
      "\u001b[?25hCollecting datasets>=1.1.3\n",
      "  Downloading datasets-1.15.1-py3-none-any.whl (290 kB)\n",
      "     |████████████████████████████████| 290 kB 53.8 MB/s            \n",
      "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
      "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "     |████████████████████████████████| 1.2 MB 40.9 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: protobuf in /home/ec2-user/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from -r examples/pytorch/summarization/requirements.txt (line 3)) (3.19.0)\n",
      "Collecting rouge-score\n",
      "  Downloading rouge_score-0.0.4-py2.py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: nltk in /home/ec2-user/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from -r examples/pytorch/summarization/requirements.txt (line 5)) (3.6.2)\n",
      "Collecting py7zr\n",
      "  Downloading py7zr-0.16.2-py3-none-any.whl (66 kB)\n",
      "     |████████████████████████████████| 66 kB 1.0 MB/s             \n",
      "\u001b[?25hRequirement already satisfied: torch>=1.3 in /home/ec2-user/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from -r examples/pytorch/summarization/requirements.txt (line 7)) (1.7.1)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from transformers==4.6) (21.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from transformers==4.6) (4.62.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/ec2-user/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from transformers==4.6) (4.8.1)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "     |████████████████████████████████| 3.3 MB 49.1 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from transformers==4.6) (2.26.0)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
      "     |████████████████████████████████| 895 kB 69.1 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from transformers==4.6) (2021.8.3)\n",
      "Collecting huggingface-hub==0.0.8\n",
      "  Downloading huggingface_hub-0.0.8-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from transformers==4.6) (1.21.3)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from transformers==4.6) (3.0.12)\n",
      "Requirement already satisfied: dill in /home/ec2-user/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from datasets>=1.1.3->-r examples/pytorch/summarization/requirements.txt (line 1)) (0.3.4)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from datasets>=1.1.3->-r examples/pytorch/summarization/requirements.txt (line 1)) (5.0.0)\n",
      "Collecting tqdm>=4.27\n",
      "  Downloading tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
      "     |████████████████████████████████| 76 kB 231 kB/s             \n",
      "\u001b[?25hRequirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from datasets>=1.1.3->-r examples/pytorch/summarization/requirements.txt (line 1)) (1.3.4)\n",
      "Requirement already satisfied: aiohttp in /home/ec2-user/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from datasets>=1.1.3->-r examples/pytorch/summarization/requirements.txt (line 1)) (3.7.4.post0)\n",
      "Collecting fsspec[http]>=2021.05.0\n",
      "  Downloading fsspec-2021.11.0-py3-none-any.whl (132 kB)\n",
      "     |████████████████████████████████| 132 kB 73.5 MB/s            \n",
      "\u001b[?25hCollecting datasets>=1.1.3\n",
      "  Downloading datasets-1.15.0-py3-none-any.whl (290 kB)\n",
      "     |████████████████████████████████| 290 kB 66.4 MB/s            \n",
      "\u001b[?25h  Downloading datasets-1.14.0-py3-none-any.whl (290 kB)\n",
      "     |████████████████████████████████| 290 kB 64.5 MB/s            \n",
      "\u001b[?25h  Downloading datasets-1.13.3-py3-none-any.whl (287 kB)\n",
      "     |████████████████████████████████| 287 kB 69.2 MB/s            \n",
      "\u001b[?25h  Downloading datasets-1.13.2-py3-none-any.whl (287 kB)\n",
      "     |████████████████████████████████| 287 kB 67.2 MB/s            \n",
      "\u001b[?25h  Downloading datasets-1.13.1-py3-none-any.whl (287 kB)\n",
      "     |████████████████████████████████| 287 kB 70.3 MB/s            \n",
      "\u001b[?25h  Downloading datasets-1.13.0-py3-none-any.whl (285 kB)\n",
      "     |████████████████████████████████| 285 kB 51.6 MB/s            \n",
      "\u001b[?25h  Downloading datasets-1.12.1-py3-none-any.whl (270 kB)\n",
      "     |████████████████████████████████| 270 kB 55.8 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: multiprocess in /home/ec2-user/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from datasets>=1.1.3->-r examples/pytorch/summarization/requirements.txt (line 1)) (0.70.12.2)\n",
      "  Downloading datasets-1.12.0-py3-none-any.whl (269 kB)\n",
      "     |████████████████████████████████| 269 kB 55.4 MB/s            \n",
      "\u001b[?25h  Downloading datasets-1.11.0-py3-none-any.whl (264 kB)\n",
      "     |████████████████████████████████| 264 kB 54.8 MB/s            \n",
      "\u001b[?25hCollecting xxhash\n",
      "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
      "     |████████████████████████████████| 243 kB 55.2 MB/s            \n",
      "\u001b[?25hCollecting absl-py\n",
      "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
      "     |████████████████████████████████| 132 kB 55.9 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: six>=1.14.0 in /home/ec2-user/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from rouge-score->-r examples/pytorch/summarization/requirements.txt (line 4)) (1.16.0)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from nltk->-r examples/pytorch/summarization/requirements.txt (line 5)) (8.0.1)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from nltk->-r examples/pytorch/summarization/requirements.txt (line 5)) (1.0.1)\n",
      "Collecting pycryptodomex>=3.6.6\n",
      "  Downloading pycryptodomex-3.11.0-cp35-abi3-manylinux2010_x86_64.whl (1.9 MB)\n",
      "     |████████████████████████████████| 1.9 MB 60.2 MB/s            \n",
      "\u001b[?25hCollecting pyppmd>=0.17.0\n",
      "  Downloading pyppmd-0.17.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (126 kB)\n",
      "     |████████████████████████████████| 126 kB 69.7 MB/s            \n",
      "\u001b[?25hCollecting pyzstd>=0.14.4\n",
      "  Downloading pyzstd-0.15.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
      "     |████████████████████████████████| 2.8 MB 52.2 MB/s            \n",
      "\u001b[?25hCollecting pybcj>=0.5.0\n",
      "  Downloading pybcj-0.5.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (48 kB)\n",
      "     |████████████████████████████████| 48 kB 9.5 MB/s             \n",
      "\u001b[?25hRequirement already satisfied: texttable in /home/ec2-user/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from py7zr->-r examples/pytorch/summarization/requirements.txt (line 6)) (1.6.4)\n",
      "Collecting multivolumefile>=0.2.3\n",
      "  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
      "Collecting brotli>=1.0.9\n",
      "  Downloading Brotli-1.0.9-cp37-cp37m-manylinux1_x86_64.whl (357 kB)\n",
      "     |████████████████████████████████| 357 kB 68.3 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: typing_extensions in /home/ec2-user/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from torch>=1.3->-r examples/pytorch/summarization/requirements.txt (line 7)) (3.10.0.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from requests->transformers==4.6) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from requests->transformers==4.6) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from requests->transformers==4.6) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from requests->transformers==4.6) (2.0.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from importlib-metadata->transformers==4.6) (3.6.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from packaging->transformers==4.6) (3.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ec2-user/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from pandas->datasets>=1.1.3->-r examples/pytorch/summarization/requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/ec2-user/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (from pandas->datasets>=1.1.3->-r examples/pytorch/summarization/requirements.txt (line 1)) (2021.3)\n",
      "Installing collected packages: xxhash, tokenizers, sacremoses, pyzstd, pyppmd, pycryptodomex, pybcj, multivolumefile, huggingface-hub, fsspec, brotli, absl-py, transformers, sentencepiece, rouge-score, py7zr, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2021.4.0\n",
      "    Uninstalling fsspec-2021.4.0:\n",
      "      Successfully uninstalled fsspec-2021.4.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "s3fs 2021.4.0 requires fsspec==2021.04.0, but you have fsspec 2021.11.0 which is incompatible.\u001b[0m\n",
      "Successfully installed absl-py-0.15.0 brotli-1.0.9 datasets-1.11.0 fsspec-2021.11.0 huggingface-hub-0.0.8 multivolumefile-0.2.3 py7zr-0.16.2 pybcj-0.5.0 pycryptodomex-3.11.0 pyppmd-0.17.3 pyzstd-0.15.0 rouge-score-0.0.4 sacremoses-0.0.46 sentencepiece-0.1.96 tokenizers-0.10.3 transformers-4.6.0 xxhash-2.0.2\n",
      "\u001b[33mWARNING: You are using pip version 21.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p37/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r examples/pytorch/summarization/requirements.txt transformers==4.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99763cb4",
   "metadata": {},
   "source": [
    "# 预训练模型下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a547226",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p models/pretrain/pegasus\n",
    "!mkdir -p models/pretrain/bart\n",
    "\n",
    "!mkdir -p ./models/local_train/pegasus-hp\n",
    "!mkdir -p ./models/local_train/bart-hp\n",
    "\n",
    "!aws s3 cp s3://datalab2021/hupo_nlp/models/pegasus/checkpoint-46314.zip models/pretrain/pegasus\n",
    "!aws s3 cp s3://datalab2021/hupo_nlp/models/bart/checkpoint-46314.zip models/pretrain/bart\n",
    "    \n",
    "!unzip models/pretrain/pegasus/checkpoint-46314.zip -d models/pretrain/pegasus > /dev/null 2>&1\n",
    "!unzip models/pretrain/bart/checkpoint-46314.zip -d models/pretrain/bart > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb1e869",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9adbbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "loading configuration file https://huggingface.co/google/pegasus-large/resolve/main/config.json from cache at /home/ec2-user/.cache/huggingface/transformers/3fa0446657dd3714a950ba400a3fa72686d0f815da436514e4823a973ef23e20.f2dc0735a07d1a70170e8e0e4d5fb57ad90d8ea5201a0dbd4b33f2f499444852\n",
      "Model config PegasusConfig {\n",
      "  \"_name_or_path\": \"google/pegasus-large\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": true,\n",
      "  \"architectures\": [\n",
      "    \"PegasusForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 16,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 16,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"extra_pos_embeddings\": 1,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 0.8,\n",
      "  \"max_length\": 256,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"pegasus\",\n",
      "  \"normalize_before\": true,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 8,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization_aeslc\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 32,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_arxiv\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_big_patent\": {\n",
      "      \"length_penalty\": 0.7,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_billsum\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_cnn_dailymail\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 128,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_gigaword\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 32,\n",
      "      \"max_position_embeddings\": 128\n",
      "    },\n",
      "    \"summarization_large\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_multi_news\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_newsroom\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 128,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_pubmed\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_reddit_tifu\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 128,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_wikihow\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 64,\n",
      "      \"max_position_embeddings\": 512\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.6.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 96103\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/pegasus-large/resolve/main/config.json from cache at /home/ec2-user/.cache/huggingface/transformers/3fa0446657dd3714a950ba400a3fa72686d0f815da436514e4823a973ef23e20.f2dc0735a07d1a70170e8e0e4d5fb57ad90d8ea5201a0dbd4b33f2f499444852\n",
      "Model config PegasusConfig {\n",
      "  \"_name_or_path\": \"google/pegasus-large\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": true,\n",
      "  \"architectures\": [\n",
      "    \"PegasusForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 16,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 16,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"extra_pos_embeddings\": 1,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 0.8,\n",
      "  \"max_length\": 256,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"pegasus\",\n",
      "  \"normalize_before\": true,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 8,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization_aeslc\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 32,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_arxiv\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_big_patent\": {\n",
      "      \"length_penalty\": 0.7,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_billsum\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_cnn_dailymail\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 128,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_gigaword\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 32,\n",
      "      \"max_position_embeddings\": 128\n",
      "    },\n",
      "    \"summarization_large\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_multi_news\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_newsroom\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 128,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_pubmed\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_reddit_tifu\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 128,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_wikihow\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 64,\n",
      "      \"max_position_embeddings\": 512\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.6.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 96103\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/google/pegasus-large/resolve/main/spiece.model from cache at /home/ec2-user/.cache/huggingface/transformers/66f187d645734a6204f3fd24593fbf0d9e36b528dd85b3adae9a566b17b4768f.1acf68c74589da6c7fa3548093824dfc450a54637f4356929bbfea7e294a68f8\n",
      "loading file https://huggingface.co/google/pegasus-large/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/google/pegasus-large/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/google/pegasus-large/resolve/main/special_tokens_map.json from cache at /home/ec2-user/.cache/huggingface/transformers/fbf9c7cf2d49b24712b53a2760e7c62a2acecd1496908822df00b8ec2683ca6d.294ebaa4cd17bb284635004c92d2c4d522ec488c828dcce0c2471b6f28e3fe82\n",
      "loading file https://huggingface.co/google/pegasus-large/resolve/main/tokenizer_config.json from cache at /home/ec2-user/.cache/huggingface/transformers/74256fafbb3cb536e351e6731914d42f732e77d33e537b6c19fb72f4b74f50ea.43f396f0ee3b974f9128267d49f69a26b11f3ed290851ac5788a549cc2979671\n",
      "loading weights file https://huggingface.co/google/pegasus-large/resolve/main/pytorch_model.bin from cache at /home/ec2-user/.cache/huggingface/transformers/ef3a8274e003ba4d3ae63f2728378e73affec0029e797c0bbb80be8856130c4f.a99cb24bd92c7087e95d96a1c3eb660b51e498705f8bd068a58c69c20616f514\n",
      "All model checkpoint weights were used when initializing PegasusForConditionalGeneration.\n",
      "\n",
      "All the weights of PegasusForConditionalGeneration were initialized from the model checkpoint at google/pegasus-large.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use PegasusForConditionalGeneration for predictions without further training.\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.94ba/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 19.66ba/s]\n",
      "***** Running training *****\n",
      "  Num examples = 1000\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 500\n",
      " 22%|█████████▏                               | 112/500 [01:30<05:06,  1.27it/s]"
     ]
    }
   ],
   "source": [
    "!python -u examples/pytorch/summarization/run_summarization.py \\\n",
    "--model_name_or_path google/pegasus-large \\\n",
    "--do_train \\\n",
    "--do_eval \\\n",
    "--per_device_train_batch_size=2 \\\n",
    "--per_device_eval_batch_size=1 \\\n",
    "--save_strategy epoch \\\n",
    "--evaluation_strategy epoch \\\n",
    "--overwrite_output_dir \\\n",
    "--predict_with_generate \\\n",
    "--train_file './data/hp/summary/news_summary_cleaned_small_train.csv' \\\n",
    "--validation_file './data/hp/summary/news_summary_cleaned_small_test.csv' \\\n",
    "--text_column 'text' \\\n",
    "--summary_column 'headlines' \\\n",
    "--output_dir='./models/local_train/pegasus-hp' \\\n",
    "--num_train_epochs=1.0 \\\n",
    "--eval_steps=500 \\\n",
    "--save_total_limit=3 \\\n",
    "--source_prefix \"summarize: \" > train_pegasus.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15081987",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -u examples/pytorch/summarization/run_summarization.py \\\n",
    "--model_name_or_path facebook/bart-large-cnn \\\n",
    "--do_train \\\n",
    "--do_eval \\\n",
    "--per_device_train_batch_size=1 \\\n",
    "--per_device_eval_batch_size=1 \\\n",
    "--save_strategy epoch \\\n",
    "--evaluation_strategy epoch \\\n",
    "--overwrite_output_dir \\\n",
    "--predict_with_generate \\\n",
    "--train_file './data/hp/summary/news_summary_cleaned_small_train.csv' \\\n",
    "--validation_file './data/hp/summary/news_summary_cleaned_small_test.csv' \\\n",
    "--text_column 'text' \\\n",
    "--summary_column 'headlines' \\\n",
    "--output_dir='./models/local_train/bart-hp' \\\n",
    "--num_train_epochs=1.0 \\\n",
    "--eval_steps=1000 \\\n",
    "--save_total_limit=3 \\\n",
    "--source_prefix \"summarize: \" > train_bart.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7d868f",
   "metadata": {},
   "source": [
    "# 本地推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3507b372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原文: Hybrid electric aircraft startup Zunum Aero, founded by Indian-origin entrepreneur Ashish Kumar, has received investments from aerospace companies Boeing and JetBlue. The startup intends to make regional aircrafts with space for 10 to 50 passengers for flights up to 1,600 km. \"Our goal is to be part of a disruptive force rather than the one being disrupted,\" said JetBlue.\n",
      "真实标签: Boeing, JetBlue back Indian-origin man's aircraft startup\n",
      "模型预测: Hybrid electric aircraft startup Zunum Aero, founded by Indian-origin entrepreneur Ashish Kumar, has received investments from aerospace companies Boeing and JetBlue.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('./data/hp/summary/news_summary_cleaned_small_test.csv')\n",
    "print('原文:',df.loc[0,'text'])\n",
    "print('真实标签:',df.loc[0,'headlines'])\n",
    "from transformers import pipeline\n",
    "summarizer = pipeline(\"summarization\", model=\"./models/local_train/pegasus-hp/checkpoint-500\")\n",
    "print('模型预测:',summarizer(df.loc[0,'text'], max_length=50)[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d7512f",
   "metadata": {},
   "source": [
    "# 增强训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f646d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "loading configuration file models/pretrain/pegasus/checkpoint-46314/config.json\n",
      "Model config PegasusConfig {\n",
      "  \"_name_or_path\": \"google/pegasus-large\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": true,\n",
      "  \"architectures\": [\n",
      "    \"PegasusForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 16,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 16,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"extra_pos_embeddings\": 1,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 0.8,\n",
      "  \"max_length\": 256,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"pegasus\",\n",
      "  \"normalize_before\": true,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 8,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization_aeslc\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 32,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_arxiv\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_big_patent\": {\n",
      "      \"length_penalty\": 0.7,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_billsum\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_cnn_dailymail\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 128,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_gigaword\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 32,\n",
      "      \"max_position_embeddings\": 128\n",
      "    },\n",
      "    \"summarization_large\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_multi_news\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_newsroom\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 128,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_pubmed\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_reddit_tifu\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 128,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_wikihow\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 64,\n",
      "      \"max_position_embeddings\": 512\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.6.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 96103\n",
      "}\n",
      "\n",
      "loading configuration file models/pretrain/pegasus/checkpoint-46314/config.json\n",
      "Model config PegasusConfig {\n",
      "  \"_name_or_path\": \"google/pegasus-large\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": true,\n",
      "  \"architectures\": [\n",
      "    \"PegasusForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 16,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 16,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"extra_pos_embeddings\": 1,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 0.8,\n",
      "  \"max_length\": 256,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"pegasus\",\n",
      "  \"normalize_before\": true,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 8,\n",
      "  \"num_hidden_layers\": 16,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization_aeslc\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 32,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_arxiv\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_big_patent\": {\n",
      "      \"length_penalty\": 0.7,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_billsum\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_cnn_dailymail\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 128,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_gigaword\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 32,\n",
      "      \"max_position_embeddings\": 128\n",
      "    },\n",
      "    \"summarization_large\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_multi_news\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_newsroom\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 128,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_pubmed\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 1024\n",
      "    },\n",
      "    \"summarization_reddit_tifu\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 128,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_wikihow\": {\n",
      "      \"length_penalty\": 0.6,\n",
      "      \"max_length\": 256,\n",
      "      \"max_position_embeddings\": 512\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 0.8,\n",
      "      \"max_length\": 64,\n",
      "      \"max_position_embeddings\": 512\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.6.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 96103\n",
      "}\n",
      "\n",
      "Didn't find file models/pretrain/pegasus/checkpoint-46314/added_tokens.json. We won't load it.\n",
      "loading file models/pretrain/pegasus/checkpoint-46314/spiece.model\n",
      "loading file models/pretrain/pegasus/checkpoint-46314/tokenizer.json\n",
      "loading file None\n",
      "loading file models/pretrain/pegasus/checkpoint-46314/special_tokens_map.json\n",
      "loading file models/pretrain/pegasus/checkpoint-46314/tokenizer_config.json\n",
      "loading weights file models/pretrain/pegasus/checkpoint-46314/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing PegasusForConditionalGeneration.\n",
      "\n",
      "All the weights of PegasusForConditionalGeneration were initialized from the model checkpoint at models/pretrain/pegasus/checkpoint-46314.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use PegasusForConditionalGeneration for predictions without further training.\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.69ba/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 19.72ba/s]\n",
      "***** Running training *****\n",
      "  Num examples = 1000\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 500\n",
      "100%|█████████████████████████████████████████| 500/500 [06:47<00:00,  1.24it/s]***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 1\n",
      "\n",
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▊                                          | 2/100 [00:01<00:56,  1.72it/s]\u001b[A\n",
      "  3%|█▎                                         | 3/100 [00:02<01:23,  1.16it/s]\u001b[A\n",
      "  4%|█▋                                         | 4/100 [00:03<01:45,  1.09s/it]\u001b[A\n",
      "  5%|██▏                                        | 5/100 [00:05<02:04,  1.31s/it]\u001b[A\n",
      "  6%|██▌                                        | 6/100 [00:07<02:10,  1.39s/it]\u001b[A\n",
      "  7%|███                                        | 7/100 [00:08<02:12,  1.42s/it]\u001b[A\n",
      "  8%|███▍                                       | 8/100 [00:10<02:18,  1.50s/it]\u001b[A\n",
      "  9%|███▊                                       | 9/100 [00:11<02:09,  1.43s/it]\u001b[A\n",
      " 10%|████▏                                     | 10/100 [00:12<02:05,  1.40s/it]\u001b[A\n",
      " 11%|████▌                                     | 11/100 [00:14<02:02,  1.38s/it]\u001b[A\n",
      " 12%|█████                                     | 12/100 [00:16<02:11,  1.49s/it]\u001b[A\n",
      " 13%|█████▍                                    | 13/100 [00:17<02:01,  1.39s/it]\u001b[A\n",
      " 14%|█████▉                                    | 14/100 [00:18<02:00,  1.40s/it]\u001b[A\n",
      " 15%|██████▎                                   | 15/100 [00:19<01:56,  1.38s/it]\u001b[A\n",
      " 16%|██████▋                                   | 16/100 [00:21<01:56,  1.38s/it]\u001b[A\n",
      " 17%|███████▏                                  | 17/100 [00:22<01:52,  1.36s/it]\u001b[A\n",
      " 18%|███████▌                                  | 18/100 [00:23<01:46,  1.30s/it]\u001b[A\n",
      " 19%|███████▉                                  | 19/100 [00:25<01:47,  1.33s/it]\u001b[A\n",
      " 20%|████████▍                                 | 20/100 [00:26<01:38,  1.24s/it]\u001b[A\n",
      " 21%|████████▊                                 | 21/100 [00:27<01:42,  1.30s/it]\u001b[A\n",
      " 22%|█████████▏                                | 22/100 [00:29<01:46,  1.36s/it]\u001b[A\n",
      " 23%|█████████▋                                | 23/100 [00:30<01:41,  1.32s/it]\u001b[A\n",
      " 24%|██████████                                | 24/100 [00:31<01:41,  1.33s/it]\u001b[A\n",
      " 25%|██████████▌                               | 25/100 [00:32<01:38,  1.31s/it]\u001b[A\n",
      " 26%|██████████▉                               | 26/100 [00:34<01:50,  1.50s/it]\u001b[A\n",
      " 27%|███████████▎                              | 27/100 [00:36<01:52,  1.54s/it]\u001b[A\n",
      " 28%|███████████▊                              | 28/100 [00:38<01:52,  1.56s/it]\u001b[A\n",
      " 29%|████████████▏                             | 29/100 [00:39<01:43,  1.45s/it]\u001b[A\n",
      " 30%|████████████▌                             | 30/100 [00:40<01:34,  1.35s/it]\u001b[A\n",
      " 31%|█████████████                             | 31/100 [00:41<01:35,  1.38s/it]\u001b[A\n",
      " 32%|█████████████▍                            | 32/100 [00:43<01:31,  1.35s/it]\u001b[A\n",
      " 33%|█████████████▊                            | 33/100 [00:44<01:31,  1.37s/it]\u001b[A\n",
      " 34%|██████████████▎                           | 34/100 [00:46<01:31,  1.39s/it]\u001b[A\n",
      " 35%|██████████████▋                           | 35/100 [00:47<01:40,  1.54s/it]\u001b[A\n",
      " 36%|███████████████                           | 36/100 [00:49<01:36,  1.51s/it]\u001b[A\n",
      " 37%|███████████████▌                          | 37/100 [00:50<01:33,  1.49s/it]\u001b[A\n",
      " 38%|███████████████▉                          | 38/100 [00:52<01:28,  1.42s/it]\u001b[A\n",
      " 39%|████████████████▍                         | 39/100 [00:53<01:32,  1.52s/it]\u001b[A\n",
      " 40%|████████████████▊                         | 40/100 [00:55<01:26,  1.44s/it]\u001b[A\n",
      " 41%|█████████████████▏                        | 41/100 [00:56<01:27,  1.48s/it]\u001b[A\n",
      " 42%|█████████████████▋                        | 42/100 [00:58<01:27,  1.51s/it]\u001b[A\n",
      " 43%|██████████████████                        | 43/100 [00:59<01:24,  1.48s/it]\u001b[A\n",
      " 44%|██████████████████▍                       | 44/100 [01:01<01:28,  1.58s/it]\u001b[A\n",
      " 45%|██████████████████▉                       | 45/100 [01:02<01:24,  1.53s/it]\u001b[A\n",
      " 46%|███████████████████▎                      | 46/100 [01:04<01:18,  1.46s/it]\u001b[A\n",
      " 47%|███████████████████▋                      | 47/100 [01:05<01:13,  1.39s/it]\u001b[A\n",
      " 48%|████████████████████▏                     | 48/100 [01:06<01:12,  1.40s/it]\u001b[A\n",
      " 49%|████████████████████▌                     | 49/100 [01:08<01:11,  1.40s/it]\u001b[A\n",
      " 50%|█████████████████████                     | 50/100 [01:09<01:08,  1.38s/it]\u001b[A\n",
      " 51%|█████████████████████▍                    | 51/100 [01:11<01:11,  1.46s/it]\u001b[A\n",
      " 52%|█████████████████████▊                    | 52/100 [01:12<01:08,  1.43s/it]\u001b[A\n",
      " 53%|██████████████████████▎                   | 53/100 [01:14<01:09,  1.48s/it]\u001b[A\n",
      " 54%|██████████████████████▋                   | 54/100 [01:15<01:07,  1.48s/it]\u001b[A\n",
      " 55%|███████████████████████                   | 55/100 [01:17<01:06,  1.47s/it]\u001b[A\n",
      " 56%|███████████████████████▌                  | 56/100 [01:18<01:04,  1.46s/it]\u001b[A\n",
      " 57%|███████████████████████▉                  | 57/100 [01:20<01:04,  1.50s/it]\u001b[A\n",
      " 58%|████████████████████████▎                 | 58/100 [01:21<01:01,  1.47s/it]\u001b[A\n",
      " 59%|████████████████████████▊                 | 59/100 [01:23<01:04,  1.58s/it]\u001b[A\n",
      " 60%|█████████████████████████▏                | 60/100 [01:24<00:59,  1.49s/it]\u001b[A\n",
      " 61%|█████████████████████████▌                | 61/100 [01:25<00:55,  1.43s/it]\u001b[A\n",
      " 62%|██████████████████████████                | 62/100 [01:27<00:55,  1.45s/it]\u001b[A\n",
      " 63%|██████████████████████████▍               | 63/100 [01:28<00:55,  1.49s/it]\u001b[A\n",
      " 64%|██████████████████████████▉               | 64/100 [01:30<00:52,  1.47s/it]\u001b[A\n",
      " 65%|███████████████████████████▎              | 65/100 [01:31<00:49,  1.41s/it]\u001b[A\n",
      " 66%|███████████████████████████▋              | 66/100 [01:32<00:43,  1.28s/it]\u001b[A\n",
      " 67%|████████████████████████████▏             | 67/100 [01:34<00:43,  1.32s/it]\u001b[A\n",
      " 68%|████████████████████████████▌             | 68/100 [01:35<00:41,  1.30s/it]\u001b[A\n",
      " 69%|████████████████████████████▉             | 69/100 [01:37<00:44,  1.43s/it]\u001b[A\n",
      " 70%|█████████████████████████████▍            | 70/100 [01:38<00:40,  1.34s/it]\u001b[A\n",
      " 71%|█████████████████████████████▊            | 71/100 [01:39<00:38,  1.34s/it]\u001b[A\n",
      " 72%|██████████████████████████████▏           | 72/100 [01:40<00:38,  1.37s/it]\u001b[A\n",
      " 73%|██████████████████████████████▋           | 73/100 [01:42<00:38,  1.43s/it]\u001b[A\n",
      " 74%|███████████████████████████████           | 74/100 [01:43<00:36,  1.41s/it]\u001b[A\n",
      " 75%|███████████████████████████████▌          | 75/100 [01:45<00:35,  1.41s/it]\u001b[A\n",
      " 76%|███████████████████████████████▉          | 76/100 [01:46<00:33,  1.39s/it]\u001b[A\n",
      " 77%|████████████████████████████████▎         | 77/100 [01:48<00:34,  1.51s/it]\u001b[A\n",
      " 78%|████████████████████████████████▊         | 78/100 [01:49<00:31,  1.42s/it]\u001b[A\n",
      " 79%|█████████████████████████████████▏        | 79/100 [01:50<00:28,  1.35s/it]\u001b[A\n",
      " 80%|█████████████████████████████████▌        | 80/100 [01:52<00:28,  1.43s/it]\u001b[A\n",
      " 81%|██████████████████████████████████        | 81/100 [01:53<00:27,  1.45s/it]\u001b[A\n",
      " 82%|██████████████████████████████████▍       | 82/100 [01:55<00:25,  1.42s/it]\u001b[A\n",
      " 83%|██████████████████████████████████▊       | 83/100 [01:56<00:24,  1.42s/it]\u001b[A\n",
      " 84%|███████████████████████████████████▎      | 84/100 [01:57<00:21,  1.35s/it]\u001b[A\n",
      " 85%|███████████████████████████████████▋      | 85/100 [01:59<00:20,  1.38s/it]\u001b[A\n",
      " 86%|████████████████████████████████████      | 86/100 [02:00<00:18,  1.33s/it]\u001b[A\n",
      " 87%|████████████████████████████████████▌     | 87/100 [02:02<00:17,  1.38s/it]\u001b[A\n",
      " 88%|████████████████████████████████████▉     | 88/100 [02:03<00:15,  1.33s/it]\u001b[A\n",
      " 89%|█████████████████████████████████████▍    | 89/100 [02:04<00:14,  1.35s/it]\u001b[A\n",
      " 90%|█████████████████████████████████████▊    | 90/100 [02:05<00:13,  1.33s/it]\u001b[A\n",
      " 91%|██████████████████████████████████████▏   | 91/100 [02:07<00:12,  1.39s/it]\u001b[A\n",
      " 92%|██████████████████████████████████████▋   | 92/100 [02:09<00:11,  1.47s/it]\u001b[A\n",
      " 93%|███████████████████████████████████████   | 93/100 [02:10<00:10,  1.48s/it]\u001b[A\n",
      " 94%|███████████████████████████████████████▍  | 94/100 [02:12<00:08,  1.47s/it]\u001b[A\n",
      " 95%|███████████████████████████████████████▉  | 95/100 [02:13<00:07,  1.41s/it]\u001b[A\n",
      " 96%|████████████████████████████████████████▎ | 96/100 [02:14<00:05,  1.46s/it]\u001b[A\n",
      " 97%|████████████████████████████████████████▋ | 97/100 [02:16<00:04,  1.59s/it]\u001b[A\n",
      " 98%|█████████████████████████████████████████▏| 98/100 [02:18<00:03,  1.59s/it]\u001b[A\n",
      " 99%|█████████████████████████████████████████▌| 99/100 [02:19<00:01,  1.54s/it]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "100%|█████████████████████████████████████████| 500/500 [09:10<00:00,  1.24it/s]\n",
      "100%|█████████████████████████████████████████| 100/100 [02:21<00:00,  1.43s/it]\u001b[A\n",
      "                                                                                \u001b[ASaving model checkpoint to ./models/local_train/pegasus-hp/checkpoint-500\n",
      "Configuration saved in ./models/local_train/pegasus-hp/checkpoint-500/config.json\n",
      "Model weights saved in ./models/local_train/pegasus-hp/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/local_train/pegasus-hp/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ./models/local_train/pegasus-hp/checkpoint-500/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████████| 500/500 [10:00<00:00,  1.20s/it]\n",
      "Saving model checkpoint to ./models/local_train/pegasus-hp\n",
      "Configuration saved in ./models/local_train/pegasus-hp/config.json\n",
      "Model weights saved in ./models/local_train/pegasus-hp/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/local_train/pegasus-hp/tokenizer_config.json\n",
      "Special tokens file saved in ./models/local_train/pegasus-hp/special_tokens_map.json\n",
      "***** train metrics *****\n",
      "  epoch                      =        1.0\n",
      "  init_mem_cpu_alloc_delta   =     -335MB\n",
      "  init_mem_cpu_peaked_delta  =     1398MB\n",
      "  init_mem_gpu_alloc_delta   =     2178MB\n",
      "  init_mem_gpu_peaked_delta  =        0MB\n",
      "  train_mem_cpu_alloc_delta  =      180MB\n",
      "  train_mem_cpu_peaked_delta =     1126MB\n",
      "  train_mem_gpu_alloc_delta  =     6521MB\n",
      "  train_mem_gpu_peaked_delta =     1472MB\n",
      "  train_runtime              = 0:10:00.84\n",
      "  train_samples              =       1000\n",
      "  train_samples_per_second   =      0.832\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 100\n",
      "  Batch size = 1\n",
      "100%|█████████████████████████████████████████| 100/100 [02:21<00:00,  1.41s/it]\n",
      "***** eval metrics *****\n",
      "  epoch                     =        1.0\n",
      "  eval_gen_len              =      13.03\n",
      "  eval_loss                 =     0.4783\n",
      "  eval_mem_cpu_alloc_delta  =        0MB\n",
      "  eval_mem_cpu_peaked_delta =        0MB\n",
      "  eval_mem_gpu_alloc_delta  =        0MB\n",
      "  eval_mem_gpu_peaked_delta =      162MB\n",
      "  eval_rouge1               =    77.4478\n",
      "  eval_rouge2               =    61.5152\n",
      "  eval_rougeL               =    74.7554\n",
      "  eval_rougeLsum            =    74.8624\n",
      "  eval_runtime              = 0:02:22.73\n",
      "  eval_samples              =        100\n",
      "  eval_samples_per_second   =      0.701\n"
     ]
    }
   ],
   "source": [
    "!python -u examples/pytorch/summarization/run_summarization.py \\\n",
    "--model_name_or_path models/pretrain/pegasus/checkpoint-46314 \\\n",
    "--do_train \\\n",
    "--do_eval \\\n",
    "--per_device_train_batch_size=2 \\\n",
    "--per_device_eval_batch_size=1 \\\n",
    "--save_strategy epoch \\\n",
    "--evaluation_strategy epoch \\\n",
    "--overwrite_output_dir \\\n",
    "--predict_with_generate \\\n",
    "--train_file './data/hp/summary/news_summary_cleaned_small_train.csv' \\\n",
    "--validation_file './data/hp/summary/news_summary_cleaned_small_test.csv' \\\n",
    "--text_column 'text' \\\n",
    "--summary_column 'headlines' \\\n",
    "--output_dir='./models/local_train/pegasus-hp' \\\n",
    "--num_train_epochs=1.0 \\\n",
    "--eval_steps=500 \\\n",
    "--save_total_limit=3 \\\n",
    "--source_prefix \"summarize: \" > train_pegasus_2.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782cda32",
   "metadata": {},
   "source": [
    "# 本地推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "746f1c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原文: Hybrid electric aircraft startup Zunum Aero, founded by Indian-origin entrepreneur Ashish Kumar, has received investments from aerospace companies Boeing and JetBlue. The startup intends to make regional aircrafts with space for 10 to 50 passengers for flights up to 1,600 km. \"Our goal is to be part of a disruptive force rather than the one being disrupted,\" said JetBlue.\n",
      "真实标签: Boeing, JetBlue back Indian-origin man's aircraft startup\n",
      "模型预测: Boeing, JetBlue back Indian-origin man's aircraft startup\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('./data/hp/summary/news_summary_cleaned_small_test.csv')\n",
    "print('原文:',df.loc[0,'text'])\n",
    "print('真实标签:',df.loc[0,'headlines'])\n",
    "from transformers import pipeline\n",
    "summarizer = pipeline(\"summarization\", model=\"./models/local_train/pegasus-hp/checkpoint-500\")\n",
    "print('模型预测:',summarizer(df.loc[0,'text'], max_length=50)[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc535902",
   "metadata": {},
   "source": [
    "# 模型部署"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16d96264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!cp -r ./models/local_train/pegasus-hp/checkpoint-500 ./endpoint/pegasus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4a7306",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sh build_and push.sh pegasus-hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "30b9fba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "model_name:  pegasus\n",
      "endpoint_ecr_image_path:  847380964353.dkr.ecr.ap-northeast-1.amazonaws.com/pegasus-hp\n",
      "<<< Completed model endpoint deployment. pegasus\n"
     ]
    }
   ],
   "source": [
    "#注意修改：847380964353.dkr.ecr.ap-northeast-1.amazonaws.com/pegasus-hp为自己对应的\n",
    "%cd endpoint\n",
    "\n",
    "!python create_endpoint.py \\\n",
    "--endpoint_ecr_image_path \"847380964353.dkr.ecr.ap-northeast-1.amazonaws.com/pegasus-hp\" \\\n",
    "--endpoint_name 'pegasus' \\\n",
    "--instance_type \"ml.p3.2xlarge\"\n",
    "\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d032dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from boto3.session import Session\n",
    "import json\n",
    "df=pd.read_csv('./data/hp/summary/news_summary_cleaned_small_test.csv')\n",
    "print('原文:',df.loc[0,'text'])\n",
    "print('真实标签:',df.loc[0,'headlines'])\n",
    "data={\"data\": df.loc[0,'text']}\n",
    "session = Session()\n",
    "    \n",
    "runtime = session.client(\"runtime.sagemaker\")\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName='pegasus',\n",
    "    ContentType=\"application/json\",\n",
    "    Body=json.dumps(data),\n",
    ")\n",
    "\n",
    "result = json.loads(response[\"Body\"].read())\n",
    "print (result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p37",
   "language": "python",
   "name": "conda_pytorch_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
