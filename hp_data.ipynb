{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d43df51c",
   "metadata": {},
   "source": [
    "# 数据下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "227de4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://datalab2021/hupo_nlp/data/news_summary_total.csv to data/hp/summary/news_summary_total.csv\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p ./data/hp/summary\n",
    "!aws s3 cp s3://datalab2021/hupo_nlp/data/news_summary_total.csv ./data/hp/summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81aaf69",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a16abf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import torch\n",
    "import re\n",
    "import os\n",
    "import string\n",
    "import datasets\n",
    "from datasets import load_dataset, load_metric,DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b5a3d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Settings:\n",
    "\n",
    "\n",
    "    TRAIN_DATA = \"./data/hp/summary/news_summary_total.csv\"\n",
    "\n",
    "    Columns = ['headlines', 'text']\n",
    "\n",
    "    encoding = 'latin-1'\n",
    "#     columns_dict = {\"headlines\": \"target_text\", \"text\": \"source_text\"}\n",
    "    columns_dict = {\"headlines\": \"headlines\", \"text\": \"text\"}\n",
    "    df_column_list = ['text', 'headlines']\n",
    "    SUMMARIZE_KEY = \"\"\n",
    "    SOURCE_TEXT_KEY = 'text'\n",
    "    TEST_SIZE = 0.2\n",
    "    BATCH_SIZE = 16\n",
    "    source_max_token_len = 128\n",
    "    target_max_token_len = 50\n",
    "    train_df_len = 82332\n",
    "    test_df_len = 20583\n",
    "class Preprocess:\n",
    "    def __init__(self):\n",
    "        self.settings = Settings\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        text = text.lower()\n",
    "        text = re.sub('\\[.*?\\]', '', text)\n",
    "        text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "        text = re.sub('<.*?>+', '', text)\n",
    "        text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "        text = re.sub('\\n', '', text)\n",
    "        text = re.sub('\\w*\\d\\w*', '', text)\n",
    "        return text\n",
    "\n",
    "    def preprocess_data(self, data_path):\n",
    "        df = pd.read_csv(data_path, encoding=self.settings.encoding, usecols=self.settings.Columns)\n",
    "        # simpleT5 expects dataframe to have 2 columns: \"source_text\" and \"target_text\"\n",
    "        df = df.rename(columns=self.settings.columns_dict)\n",
    "        df = df[self.settings.df_column_list]\n",
    "        # T5 model expects a task related prefix: since it is a summarization task, we will add a prefix \"summarize: \"\n",
    "        df[self.settings.SOURCE_TEXT_KEY] = df[self.settings.SOURCE_TEXT_KEY]\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b3940d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                      text  \\\n",
       "0       Saurav Kant, an alumnus of upGrad and IIIT-B's...   \n",
       "1       Kunal Shah's credit card bill payment platform...   \n",
       "2       New Zealand defeated India by 8 wickets in the...   \n",
       "3       With Aegon Life iTerm Insurance plan, customer...   \n",
       "4       Speaking about the sexual harassment allegatio...   \n",
       "...                                                   ...   \n",
       "102910  Fruit juice concentrate maker Rasna is eyeing ...   \n",
       "102911  Former Indian cricketer Sachin Tendulkar atten...   \n",
       "102912  Aamir Khan, while talking about reality shows ...   \n",
       "102913  The Maharashtra government has initiated an in...   \n",
       "102914  At least 400 languages or more than half langu...   \n",
       "\n",
       "                                                headlines  \n",
       "0       upGrad learner switches to career in ML & Al w...  \n",
       "1       Delhi techie wins free food from Swiggy for on...  \n",
       "2       New Zealand end Rohit Sharma-led India's 12-ma...  \n",
       "3       Aegon life iTerm insurance plan helps customer...  \n",
       "4       Have known Hirani for yrs, what if MeToo claim...  \n",
       "...                                                   ...  \n",
       "102910  Rasna seeking ?250 cr revenue from snack categ...  \n",
       "102911  Sachin attends Rajya Sabha after questions on ...  \n",
       "102912  Shouldn't rob their childhood: Aamir on kids r...  \n",
       "102913  Asha Bhosle gets ?53,000 power bill for unused...  \n",
       "102914  More than half of India's languages may die in...  \n",
       "\n",
       "[102915 rows x 2 columns]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings=Settings\n",
    "preprocess=Preprocess()\n",
    "df = preprocess.preprocess_data(settings.TRAIN_DATA)\n",
    "df.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a232136",
   "metadata": {},
   "source": [
    "# 训练集-测试集划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6dc45f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((82332, 2), (20583, 2))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv('./data/hp/summary/news_summary_cleaned.csv',index=False)\n",
    "df2=pd.read_csv('./data/hp/summary/news_summary_cleaned.csv')\n",
    "order=['text','headlines']\n",
    "df3=df2[order]\n",
    "train_df, test_df = train_test_split(df3, test_size=0.2,random_state=100)\n",
    "train_df.shape,test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a361184",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('./data/hp/summary/news_summary_cleaned_train.csv',index=False)\n",
    "test_df.to_csv('./data/hp/summary/news_summary_cleaned_test.csv',index=False)\n",
    "train_df[:1000].to_csv('./data/hp/summary/news_summary_cleaned_small_train.csv',index=False)\n",
    "test_df[:100].to_csv('./data/hp/summary/news_summary_cleaned_small_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d776a1be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p37",
   "language": "python",
   "name": "conda_pytorch_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
